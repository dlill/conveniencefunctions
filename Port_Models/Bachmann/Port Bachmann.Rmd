---
title: "D2D2R"
author: "Daniel Lill"
date: "7 July 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dMod)
library(conveniencefunctions)
library(shiny)
library(miniUI)

```

```{r setup files}
setup_file <- c("~/Promotion/Software/d2d/arFramework3/Examples/Bachmann_MSB2011/Setup.m")
model_def_file <- data_files <- readme_file <- NULL


if (is.null(setup_file) & (is.null(model_def_file)| is.null(data_files))) stop("If setup_file is not provided, model_def_file and data_files must be provided")

if (!is.null(setup_file)) {
  modelpath <- setup_file %>% str_split(.Platform$file.sep, simplify = T) %>% {.[1:(length(.)-1)]} %>% as.list %>% do.call(file.path,.)
} else {
  modelpath <- model_def_file %>% str_split(.Platform$file.sep, simplify = T) %>% {.[1:(length(.)-2)]} %>% as.list %>% do.call(file.path,.)
}

if (!is.null(setup_file)) {
  model_def_file <- readLines(setup_file) %>%
  {.[!str_detect(.,"^%")]} %>% #commented lines
  {.[str_detect(.,"arLoadModel")]} %>% # only lines loading the model (should be only 1)
    str_replace_all(c("arLoadModel\\(" = "", "\\)" = "", "'" = "", ";.*$" = "")) %>% #extract only the name of the model.def
    paste0("Models/",. ,".def") %>% # make file path out of it
    list(modelpath,.) %>%
    do.call(file.path,.)
}
```


```{r model_def and data_defs, warning=FALSE}
# model_def
model_def <- read_def_content(model_def_file)

# data_defs
if (!is.null(setup_file)) data_files <- readLines(setup_file) %>%
{.[!str_detect(.,"^%")]} %>% #commented lines
{.[str_detect(.,"arLoadData")]} %>% # only lines loading the model (should be only 1)
  str_replace_all(c("arLoadData\\(" = "", "\\)" = "", "'" = "", ";.*$" = "")) %>% #extract only the name of the model.def
  str_split(",", simplify = T)

data_def_files <- data_files %>%
{paste0("Data/",.[,1] , ".def")} %>% # make file path out of it
  list(modelpath,.) %>%
  do.call(file.path,.)

data_sheet_files <-
  data_files %>% 
  {paste0(modelpath, "/", "Data/", .[,1] , ".xls")} %>% 
  map_chr(function(file) {
    if (!file.exists(file)) file <- file %>% str_replace_all("xls$", "csv")
    if (!file.exists(file)) file <- file %>% str_replace_all("csv$", "xlsx")
    return(file)
  }) 



files_exist <- file.exists(data_def_files)&file.exists(data_sheet_files)
data_files <- data_files[files_exist,]
data_def_files <- data_def_files[files_exist]
data_sheet_files <- data_sheet_files[files_exist]

data_defs <- data_def_files %>%
  lapply(. %>% read_def_content)

data_sheets <- lapply(seq_along(data_sheet_files), function(i) {
  data_files
  if(str_detect(data_sheet_files[i], "csv$")) {
    return(read.csv(data_sheet_files[i], stringsAsFactors = F))
  } else {
    return(readxl::read_excel(data_sheet_files[i]))
  }
})

data.frame(data_sheet_files, data_def_files)
```



```{r}
# Build the prediction function
# reactions <- get_reactions_or_odes(model_def)
# myodemodel <-  odemodel(reactions, modelname = "x")
# x <-  Xs(odemodel = myodemodel)
# saveRDS(x, "x.rds")
x <- readRDS("x.rds")
loadDLL(x)
```

```{r g e and p}
i <- 1
frames <- map(seq_along(data_defs), function(i) {
i<<-i

data_def <- data_defs[[i]]
cat("\n", i, "\n")
cat("\n", data_def_files[[i]], "\n")

derived_md <- model_def %>% get_derived()
derived_dd <- data_def %>% get_derived()
if(any(names(derived_dd)%in%names(derived_md))) warning( "deriveds are overwritten?")
# Observables
# 1. Read observables in model_def and the data_defs

observables <-  get_observables(model_def, rbind(derived_md, derived_dd))
observables_data_def <- get_observables(data_def, derived = c(derived_md,derived_dd))
# 2. For each data_def, replace the specific obervables
observables <- observables %>% replace(names(observables_data_def),observables_data_def) %>% as.eqnvec

# Error models
# 1. Read errors in model_def and the data_defs
errors <-  get_errors(model_def)
errors_data_def <- data_def %>% get_errors
# 2. For each data_def, replace the specific errors
errors <-  errors %>% replace(names(errors_data_def),errors_data_def) %>% as.eqnvec


# Conditions in def files
# 1.
conditions_to_datasheet <- get_conditions(model_def)
conditions_to_datasheet_data_def <- get_conditions(data_def)
# 2.
conditions_to_datasheet <- conditions_to_datasheet %>% replace(names(conditions_to_datasheet_data_def), conditions_to_datasheet_data_def)

# Data sheet
# Add conditions as columns, don't overwrite columns in the data by "conditions" as the data is the outermost "layer" of defining conditions
data_sheet <- data_sheets[[i]]
which_conditions_to_datasheet <- setdiff(names(conditions_to_datasheet), names(data_sheet))
data_sheet <- data.frame(data_sheet, t(conditions_to_datasheet[which_conditions_to_datasheet]), dataset = data_files[i], stringsAsFactors = F) 


# Deal with unused data and with conditions supplied by the data sheet which are not declared anywhere
standard_vars <- c("time", "dataset", names(observables), paste0(names(observables), "_std"), names(get_conditions(model_def)))
undeclared_vars <- names(data_sheet) %>% .[!.%in%standard_vars]
obs_estimate  <- undeclared_vars %>% str_subset("(.*_au)|(.*_std)")
cond_estimate <- undeclared_vars %>% .[!.%in%obs_estimate]

select_cols <- function(undeclared_vars, obs_estimate, cond_estimate) {
  ui <- miniPage(
    gadgetTitleBar("My Gadget"),
    miniContentPanel(
      selectInput("observables", "Observables which aren't in the def files", undeclared_vars, obs_estimate, multiple = T),
      selectInput("conditions", "Columns which contribute to conditions", undeclared_vars, cond_estimate, multiple = T),
      selectInput("excluded", "Keep in covariates(data) but don't use in condition name.", undeclared_vars, NULL, multiple = T)
      )
  )

  server <- function(input, output, session) {
    # Define reactive expressions, outputs, etc.
    
    # When the Done button is clicked, return a value
    observeEvent(input$done, {
      returnValue <- list(obs = input$observables, cond = input$conditions, excluded = input$excluded)
      stopApp(returnValue)
    })
  }

  runGadget(ui, server)
}

cols <- list(obs = NULL, cond = NULL, excluded = NULL)
if(length(obs_estimate) > 0 | length(cond_estimate) > 0) {
  cols <- select_cols(undeclared_vars, obs_estimate, cond_estimate)
}
# kick out unused data_cols
data_sheet <- data_sheet[!names(data_sheet)%in%cols$obs]
# define variables which uniquely identify conditions
condition_names <- c("dataset", names(conditions_to_datasheet_data_def), cols$cond) %>% unique %>% setdiff(cols$excluded)
  


# Gather obs and obs_sd columns and transform them into name, value, sigma. Then as.datalist
data <- data_sheet %>% 
  gather(name,value, one_of(c(names(observables), paste0(names(observables), "_std")))) %>% 
  mutate(is_sigma = str_detect(name, "_std$"), name = str_replace_all(name, "_std$", "")) %>% 
  { mydf <- .
    if (any(mydf$is_sigma)) {
    mydf <- mydf %>% 
      mutate(is_sigma = replace(is_sigma, is_sigma, "sigma"), is_sigma = replace(is_sigma, is_sigma == "FALSE", "value")) %>%
      spread(is_sigma, value) 
    } else {mydf <- mydf %>% select(-is_sigma) %>% mutate(sigma = NA)} 
  mydf
  } %>% 
  filter(!is.na(value)) %>% 
  as.data.frame() %>% cf_as.datalist(make.names.from = condition_names)

# Ensure time value and sigma are numeric and consistently use NA for missing values
covtable <- covariates(dataset)
data <- map(data, function(cn) {
  # make value numeric
  cn$value <- cn$value %>% as.numeric()
  indices <- is.nan(cn$value)
  cn$value[indices] <- NA
  
  # make sigma numeric, can be mising, but use NA instead of NaN
  cn$sigma <- cn$sigma %>% as.numeric()
  indices <- is.nan(cn$sigma)
  cn$sigma[indices] <- NA
  
  # make time numeric, drop timepoints with non-existing times
  cn$time <- cn$time %>% as.numeric()
  indices <- is.nan(cn$time)
  cn$time[indices] <- NA
}) %>% 
  as.datalist() %>% 
  `attr<-`("condition.grid", covtable)


# Create condition specific functions
# Somehow the whole search tree is again messed up in compile. It needs g e and p to be in the .GlobalEnv to modify their "modelname" attribute.
# This on the other hand then implies that I need to get these objects from the .GlobalEnv in order to write the correct objects with the correct modelname to the dMod.frame

conditions <- covariates(data) %>% rownames()
# g
g <- map(conditions, function(cn) Y(observables, x, condition = cn, modelname = "g")) %>% 
  Reduce("+", .)
assign("g", g, pos = .GlobalEnv)

# e
e <- map(conditions, function(cn) Y(errors, g*x, condition = cn, modelname = "g")) %>% 
  Reduce("+", .)
assign("e", e, pos = .GlobalEnv)

# trafo
pinner <- getParameters(g,x,e)
assign("pars_in_data", intersect(names(covariates(data)), pinner), pos = .GlobalEnv)
assign("random", union(get_random(data_def), get_random(model_def)), pos = .GlobalEnv)

# linear_pars: Would be nice to have a function to automatically detect linear parameters

trafo <- pinner %>% 
  setNames(.,.) %>% 
  branch(covariates(data)) %>% 
  insert("name ~ value", value = unlist(mget(pars_in_data)), name = pars_in_data) %>% 
  {tr <- .
  if (!is.null(random)) tr <-  insert(tr, "x_random~x_value", value = unlist(mget(random)), random = random)
  tr} %>% 
  insert("x~exp(x)", x = getSymbols(mytrafo[[i]]))



p <- P(trafo, modelname = "p")
assign("p", p, pos = .GlobalEnv)

compile(g,e,p, output = "gep", cores = detectFreeCores() - 1)
remove_c_and_o()

g <- get("g", pos = .GlobalEnv)
e <- get("e", pos = .GlobalEnv)
p <- get("p", pos = .GlobalEnv)

dMod.frame(data_files[i], g, x, p, data, e)
})

# rowbind them together
bachmann <- frames <- frames %>% bind_rows()
saveRDS(bachmann, tpaste0("bachmann.rds"))

hypothesis <- model_def_file %>% str_replace_all(".*/", "")
model <- dMod.frame(hypothesis, Reduce("+", frames$g), frames$x[[1]], Reduce("+", frames$p), Reduce("+", frames$data), e = Reduce("+", frames$e))


```






















